\section{Problem Statement}
Historically, computer architecture security relied on processor modes or privilege modes where code was allowed to execute. In these modes, separation of privileges is achieved and often referred to as ``rings'' with ``ring 0'' being the most privileged (machine mode, kernel code) and ring 3 being the least privileged (user mode, application code). Device drivers run in the rings between these two modes with virtualization being the most common use case\footnote{The virtual machine’s kernel, for example, runs in ring 1, one level up from machine mode.}. As applications became more complex, specifically with the advent of large-scale virtualization and the internet, this simple security model broke down as executed code could no longer be trusted, nor its origin verified. The problem of ``secure remote computation'' arises where the data owner must trust not only the software provider, but also the remote computer and infrastructure on which that software is executed. Homomorphic encryption solves this problem to some extent, however the performance overhead of this transaction limits its application \cite{Gentry01}. 

In an attempt to address these issues, microprocessor designers have implemented versions of a \gls{tee}, first defined by the Open Mobile Terminal Platform and ratified in 2009 \cite{OMTP01}. The OMTP standard was transferred to the Wholesale Applications Community (WAC) in 2010 and in July 2012 WAC itself was closed, with the OMTP standards being transferred to The GSM Association (originally Groupe Spécial Mobile)\cite{WAC}. In this paper we will discuss the two most prevalent implementations of this standard for the x86-64 and AArch64 architectures, as well as a completely open source hardware and software implementation of a TEE for the RISC-V architecture.
\section{The Intel SGX Solution}
Intel \gls{sgx} is built on designs of software attestation already proven in technologies like the \gls{tpm} and Intel \gls{txt}. In \gls{sgx}, these concepts of software attestation are used to create containerized sections of memory on the remote computer called ``secure enclaves'' where data and code can be loaded or executed securely. These enclaves are verified by both a cryptographic attestation key of the container’s contents as well as a hardware \gls{rot} manufacturer’s key. Unlike the \gls{tpm} and \gls{txt} technologies, \gls{sgx} securely operates only on a small amount of data and code called the \gls{tcb}, leaving the majority of memory outside this \gls{tcb}.
\section{Initial SGX Enclave Setup}
Configuration settings for \gls{sgx} exists as part of the platform firmware, and most firmware vendors provide simple tools for enabling \gls{sgx}. If \gls{sgx} is enabled, the firmware is responsible for setting aside a memory region called the \gls{prm}, and most firmware tools allow specifying the size of the space allocated. The firmware allocates the \gls{prm} by setting a pair of \glspl{msr}, collectively known as the PRMRR. The CPU will then protect the \gls{prm} from all non-enclave memory accesses including kernel, hypervisor and \gls{smm} accesses, as well as \gls{dma} from peripherals \cite{intel-sgx-explained}. 

This section of specially allocated memory is used to store the \gls{epc}, which are the 4kb pages holding both the enclave data and code. The exact layout of the \gls{prm} and \gls{epc} are model-specific, and depend on firmware settings. While untrusted system software both assigns these EPCs to an enclave and loads them with data, it is the CPU which keeps track of all the \gls{epc}s ensuring that they only belong to one enclave. Once the system software loads data into the enclave it asks the CPU to mark that enclave as initialized, after which no other data may be loaded into the enclave as this setup process is disabled for that enclave. After initialization, this enclave is measured by a cryptographic hash to ensure that any operations performed on the enclave are done so in a secure environment.
\vspace{10 mm}

\begin{figure}[htbp]
\centering
\input{tikz/sgx-flow}
\caption[Setting Up Intel SGX]{\textbf{Workflow for setting up an enclave.}}
\label{fig:sgx-setup}
\end{figure}

\section{Executing SGX Enclave Code}
Execution flow can only move into an enclave via a special CPU instruction, much like switching from user mode to kernel mode. The actual execution happens in user mode and takes advantage of address translation from the Operating System or hypervisor. The CPU executing the enclave code performs an \gls{aex} whenever execution moves outside the enclave such as servicing an interrupt or during a page fault. The CPU state is saved inside the enclave before exiting ensuring that the CPU can security restore the state of execution. There are special machine mode CPU instructions that are used both in allocating \gls{epc} pages to the enclave as well as evicting those pages into untrusted DRAM. This facilitates code outside the enclave to operate on code within the enclave. \gls{sgx} uses cryptographic protections to assure the confidentiality, integrity and freshness of the evicted \gls{epc} pages while they are stored in untrusted memory \cite{intel-sgx-explained}. In this way, Intel \gls{sgx} is able to allow a specific amount of code and data to remain protected while still allowing access to that data by code outside the trust boundary.

\begin{figure}[ht]
\makebox[\textwidth][c]{\input{tikz/sgx-lifecycle}
}\caption[Intel SGX Enclave Lifecycle]{\textbf{Intel SGX enclave life cycle.} The enclave's memory is protected in states shaded blue. Reprinted as a simplified version from \cite{intel-sgx-explained}.\label{figure:sgx-enclave-life-cycle}}
\end{figure}

In order to understand the life cycle of an enclave, we must consider the specific x86 instructions used to create and manage these enclaves. Many of these instructions which create, extend, and remove enclaves operate in ``ring 0'' (most privileged), while attestation, entering, and exiting the enclave can be done in ``ring 3'' (application code). The first of the privileged instructions is ECREATE which fills a protected data structure located inside the \gls{epc} with the size and hash of the enclave. This data structure, called the \gls{secs}, is used by the hardware and is not directly accessible to software. A developer may then add pages to the \gls{epc} with the EADD instruction, and extend the \gls{epc} page measurement with the EEXTEND instruction. The EEXTEND instruction allows for the accumulation of a hash of all the pages in the \gls{epc}. This measurement can be used later for attestation that the enclave has not been tampered with or changed in some way.

It is important to note that in its uninitialized state, none of the enclave code or data is encrypted. For example, any privileged driver running at ``ring 0'' can have access to these data and structures. Enclaves must be initially built on a system that is known to be secure, such that the measurements taken are considered a ``gold standard'' with which to preform attestation on a local or remote machine at some later time. When the EINIT instruction is called, the enclave is considered fully built, the measurement is locked down, and ``ring 3'' (user) applications can now enter the enclave and attest that it is secure. 

EBLOCK, ETRACK, EWB, and ELOAD\footnote{Actually, two load commands, ELDB and ELDU both load into memory a previously evicted page, with ELDB for blocked and ELDU for unblocked. Pages may be blocked when being prepared for eviction. All future accesses to blocked pages will result in a page fault.} are paging instructions run with ``ring 0'' privileges. The goal is to allow the paging of secure pages into and out of main memory while ensuring the confidentiality and integrity of those pages. Information stored inside the \gls{epc} called the \gls{pcmd} keeps track of the identity of the enclave the page belongs to and a pointer to an access rights structure. There is also a \gls{va} which is used to store the version numbers of pages evicted from the \gls{epc}. These versioned and access controlled pages are therefore hardware protected, and any change to the versioning, access rights, or origins of the page will result in a page fault. It is possible to have 2 instances of the same enclave, however pages cannot be swapped between them, and the hashes of these pages will not be the same.

Once an application has asked for ``ring 0'' components to build the enclave and called EENTER to enter the enclave it may begin execution. The hardware is responsible for saving and restoring (ERESUME) the architectural state of execution should any external events like interrupts or exceptions cause execution to leave the enclave (AEX). The EGETKEY and EREPORT instructions operate in user mode (``ring 3'') and seal data based on the key the developer provides. Using these two instructions SGX applications operating in ``ring 3'' are able to preform attestation of the enclave, perhaps the most vital function of any \gls{tee}.

\section{Attestation with Intel SGX}
Software attestation of enclaves is required to ensure the integrity of the enclave. This attestation can happen locally between two enclaves on the same platform or remotely between two different platforms. As previously noted, the measurement of the enclave includes a SHA-256 hash of the enclave's attributes as well as the content, position, and access rights of its pages. This measurement is stored in a register called MRENCLAVE which represents the enclave's \gls{tcb}. The EREPORT instruction is used to generate a signed report of this \gls{tcb} and the EGETKEY instruction then retrieves the key used to validate said report. Local attestation of enclaves can be done using symmetric encryption as the hardware can ensure the integrity of the single key being used to verify the MRENCLAVE value. Remote attestation must be done using asymmetric encryption (both a public and private key) and requires the remote SGX enabled platform to query an Intel attestation server. 

\section{The Arm TrustZone Solution}
When evaluating how Arm’s TrustZone works, we must remember several important distinctions. Firstly, the Arm specifications include several different architectures with several different states. Each Arm architecture and state combination may operate slightly differently in regard to how TrustZone is implemented. This paper will only consider the ARMv8-A architecture running in the AArch64 state. Secondly, hardware manufacturers may choose to implement security in many ways, and with much more flexibility than in Intel platforms. For simplicity’s sake, this paper will only cover standard Arm solutions for TrustZone implementation, provided by Arm's \gls{tfa} and \gls{optee}.
 
Arm \gls{soc} processors create a more absolute separation between the worlds of ``secure'' and ``normal or insecure'' operation than Intel \gls{sgx}. At its highest level this is accomplished using the \gls{scr} ``Non-Secure Bit'' (NS) with 1 meaning non-secure and 0 meaning secure. This is perhaps the most fundamental element that separates Arm's two security worlds. Digging a bit deeper, this separation of worlds is accomplished using three principal technologies on the bus, the \gls{soc} core, and the debug infrastructure. Firstly, the bus interface, called the \gls{amba} \gls{axi}, partitions all of the \gls{soc}’s hardware and software resources by taking advantage of a set of bits. Hardware logic present in this ``TrustZone-enabled AMBA3 AXI'' bus fabric ensures that no ``Secure World'' resources can be accessed by ``Normal World'' components. These bits include AWPROT for write transactions and ARPROT for read transactions where like the NS bit low is Secure and high is Non-secure. Secondly, \gls{soc}s which include cores like the ARMv8-A implement extensions which enable a single physical processor core to safely and efficiently execute code from both the Normal World and the Secure World in a time-sliced fashion. Lastly, the security-aware debug infrastructure controls debug access to the Secure World \cite{ArmWhitepaper}. These three technologies provide a framework or scaffolding on which to build a platform capable of secure computation.

Unlike Intel platforms which refer to their privilege levels as rings, Arm uses ``Exception Levels'' EL0 through EL3 \cite{ArmV8Fund}. Here EL3 is the highest, most privileged level where as EL0 is the lowest and least privileged level. One important thing to note here is that exceptions (e.g. data aborts, pre-fetch aborts, interrupts) can be taken from the level at which they occur to the same or any higher level, but not a lower level. So, for example, an interrupt occurring in the OS kernel (EL1) can be handled in the kernel or in the secure monitor (EL3), but not in the lower application level (EL0). Practically speaking this means that the user applications running on a system which has not been compromised will not have access to kernel or lower exceptions.

\renewcommand{\arraystretch}{2.5}
\input{tables/arm-els}

Each exception level manages its own page tables and control registers with the exception of EL0 which is managed by EL1. This is a common practice across architectures where the kernel level mode controls the page table for the applications running on top of it. As we will see, this division is taken advantage of by the ARMv8-A architecture to enable the separation of memory accesses between the Secure World and the Normal World.

\section{Arm Trusted Firmware}
Since 2013, Arm has provided \glsreset{tfa}\gls{tfa} as an open source reference implementation of the firmware required to develop Secure World software for A-Class devices (including ARMv8-A). The \gls{tfa} provides many features including secure device initialization, modular boot flow, trusted boot, and the secure monitor that allows switching between the Normal World and the Secure World. It should be noted that all of this code and documentation is freely available at \url{https://www.trustedfirmware.org/}. The Trusted Firmware Project is a `not for profit' open source project hosted by Linaro Limited (``Linaro'').

Arm Trusted Firmware uses the scaffolding provided by the A-Class devices to implement the key aspects of TrustZone, namely Trusted Boot and the Secure Monitor. There are currently over 30 platforms supported by Trusted Firmware and because the code is open source (BSD 3-clause), porting new platforms can be done by following many of the existing open source examples. Before we explore Arm Trusted Firmware, we must first understand how an Arm platform can be initialized in a secure state, specifically using \gls{tbb}. \gls{tbb} is based on two standards, the Arm Trusted Base System Architecture (TBSA) \cite{ArmSystemArch} and the Arm Trusted Board Boot Requirements (TBBR) \cite{ArmTrustedBoot}. Both of these specifications are client-based solutions and it is likely that server based solutions are in development internally at Arm.

\begin{figure}[ht]
\centering
\input{tikz/tbb-flow}
\caption[Arm's Trusted Board Boot]{\textbf{A significantly simplified boot flow for setting up a secure root of trust on an Arm system running Trusted Firmware.} Here we see the boot flow from a cold reset all the way to the Normal World bootloader which may load any untrusted OS kernel.}
\label{fig:tbb-flow}
\end{figure}

As soon as the SoC comes out of power-on-reset, execution happens in integrity protected memory like on-chip Boot ROM or Trusted SRAM. At this stage we have access to a \gls{rotpk} located in one of the \gls{soc}'s \gls{otp} Efuse registers. These keys are usually SHA-256 and the Efuse is burned by the manufacturer to ensure the integrity of the keys. This secure ROM firmware code is often called the Bootloader Stage 1 or BL1, and it is responsible for checking the validity of the \gls{rotpk}. Using this key, BL1 can verify the hash of the next bootloader stage (BL2). The code in BL1 is the only code that must run in EL3, minimizing the amount of initialization code that must run at this critical privilege level.

Once in BL2, the code is executing in Secure World EL2 and the firmware can use the \gls{rotpk} to extract the Trusted World \gls{rotpk} and the Normal World \gls{rotpk}, which are used in turn to validate the Secure World Trusted OS hash as well as the Normal World Untrusted OS hash. All of these keys and hashes are included as extensions to the x.509 standard format, however there is no need for a valid Certified Authority (CA) certificate, as we are verifying the contents of the certificates and not the validity of a certificate issuer. BL2 also does some RAM initialization before it passes off to BL3 where the Secure Monitor is implemented.

This Secure Monitor runs in EL3 and is responsible for loading both the Secure OS as well as the Normal World bootloader (like U-Boot or some UEFI implementation). This Secure Monitor stays resident in memory during the life of the system and will manage the interactions between the Normal and Secure Worlds. All of these stages (BL1 - BL3) of \gls{tbb} are implemented by Arm's \glsreset{tfa}\gls{tfa} reference implementation.

\begin{figure}[ht]
\makebox[\textwidth][c]{\input{tikz/trustzone-overview}
}\caption[Arm TrustZone Example of Normal and Secure World]{\textbf{Secure World implementation using ARM TrustZone.}
The \gls{soc} boots into the Secure World and a monitor is registered which acts as the interface between the Secure and Normal Worlds.
\label{fig:trustzone}}
\end{figure}

Once the Trusted Firmware has initialized the system in a secure state, we have initialized two worlds, the Trusted World and the Normal World. It is perhaps easiest to think about the interaction between these two worlds in much the same way we think about making calls from user mode into kernel mode in Linux systems. In Linux systems, we take advantage of system calls (syscall) to bridge a trust boundary between the kernel's concerns like interacting with a network card from the user applications concerns like displaying a web page. At no point in this interaction should the user application code have access to the network card's buffers, however the kernel is able to read data from these buffers and provide useful data to the client application. This "one way street" of data flow is how memory in the Secure World is kept separate from the Normal World using a method called a Secure Monitor Call (SMC).